---
title: "pre_lab_02.Rmd"
author: "Derek Willis/Rob Wells
date: "2025-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## This week's topics

-   Using filter() to find specific records
-   Using select() to see only certain columns
-   Using lubridate to work with dates
-   Using mutate() to add and update columns
-   Using case_when() to conditionally populate columns

### Task 1: Load libraries

**Task** Run the following code in the gray-colored codeblock below -- not in the console -- to load the tidyverse library. To run the code, click the little green play button (left facing arrow) at the top right of the codeblock. In Rmarkdown data notebooks, we write code inside of codeblocks, and explanatory text in the white area outside of it.

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
library(lubridate)
```

### Task 2: Load data

**Task** Load the UMD courses data by running the following codeblock. NOTE: it's now located in a `data` folder.

```{r}
umd_courses <- read_rds("data/umd_courses.rds")
```

### Task 3: Glimpse data

**Task** Run the following codeblock to use summary() and colnames() to get a sense of the data and the data types of each field/variable/column. Add a description of what these do to your reference notebook.

```{r}
summary(umd_courses)
colnames(umd_courses)
```

## Filter and Select

More often than not, we have more data than we want. Sometimes we need to only focus on specific slices of that data. In the tidyverse, there's two ways to go about this: filtering and selecting.

**Filtering creates a subset of the data based on criteria**. All records where the seats are greater than 14. All records where the department is "Journalism". Something like that. **Filtering works with rows -- when we filter, we get fewer rows back than we start with.**

**Selecting simply returns only the fields named**. So if you only want to see department and course ID, you select those fields. When you look at your data again, you'll have two columns. If you try to use one of your columns that you had before you used select, you'll get an error. **Selecting works with columns. You will have the same number of records when you are done, but fewer columns of data to work with.**

### Task 4: Filter by one column

**Task** Run the following code to limit our courses to the Journalism school.

```{r}
journalism_courses <- umd_courses |> filter(department == "Journalism")

head(journalism_courses)
```

And just like that, we have just Journalism results, which we can verify looking at the head, the first six rows. We also could filter by a numeric column like `term`, so we could see just courses in 2025:

**Task** Run the following code to limit our courses to those in terms in 2025:

```{r}
courses_2025 <- umd_courses |> filter(term > 202500)

head(courses_2025)
```

### Task 5: Select

We also have more columns than we might want. For example, we may only want to work with the course id and title.

To simplify our dataset, we can use select.

**Task** Run the following code to select only certain columns and answer the question below.

```{r}
selected_journalism_courses <- journalism_courses |> select(id, title)

head(selected_journalism_courses)
```

And now we only have two columns of data for whatever analysis we might want to do.

Notice that we made a new variable, selected_journalism_courses, to hold the result. Why is that important?

**Answer**I would say it's important so you have access to it later so you dont have to recreate that subsection every time you need it.

### Task 6: Combining filters

So let's say we wanted to see all the courses in the Theatre department with at least 15 seats. We can do this a number of ways. The first is we can chain together a whole lot of filters.

**Task** Run the following code

```{r}
theatre_seats_15 <- umd_courses |> filter(department == "Theatre") |> filter(seats >= 15)

nrow(theatre_seats_15)
```

That gives us 308 records But that's repetitive, no? We can do better using a single filter and boolean operators -- AND and OR. In this case, AND is `&` and OR is `|`.

**Task** Run the following code

```{r}
and_theatre_seats_15 <- umd_courses |> filter(department == "Theatre" & seats >= 15)

nrow(and_theatre_seats_15)
```

So AND gives us the same answer we got before. What does using the OR operator give us?

**Task** Run the following code and put the number of results below.

```{r}
and_theatre_seats_15 <- umd_courses |> filter(department == "Theatre" | seats >= 15)

nrow(and_theatre_seats_15)
```

**Answer** The number of the results is 5400 this represents all courses that either are a part of the theater department, any number of seats, or any course in any other department that has more than 15 seats


When it comes to filters, OR is additive; AND is restrictive.

### Task 7: Filter on partial match

Sometimes you need to find rows that contain a certain pattern rather than an exact match - like if you're looking for all of the courses with "Shakespeare" in the title. There are several ways to do this using R, but one way is to use the function `str_detect`, which stands for "string detect". You use it inside a `filter` by supplying the column and the pattern you want to match, like so:
#question from DL to RW what is the difference between string detect and grepl? I found this on stackoverflow but if you have a plain english answer I'd be interested. Thank you. https://stackoverflow.com/questions/57412700/whats-the-difference-between-the-str-detect-function-in-stringer-and-grepl-and

**Task** Run the following code

```{r}
umd_courses |>
  filter(str_detect(title, "shakespeare"))
#changed to lowercase shakespeare as instructed
```

```{r}
#I'm going to try and see what happens, if in the future you want me to delete this kind of understanding check experiments let me know.
umd_courses |>
  filter(grepl("?Shakespeare", title))
```
#looks the same. Doing this because I'm curious not because I am questioning why you are teaching us string detect

The latest version of the tidyverse also has a function called `str_like` which uses the wildcard search operator % to do partial matching.

A general tip about using filter: it's easier to work your way towards the filter syntax you need in steps rather than try and write it once and trust the result. Each time you modify your filter, check the results to see if they make sense. This adds a little time to your process but you'll thank yourself for doing it because it helps avoid mistakes. Note that whatever you're trying to match using `filter` - whether an exact match or a partial one - R is case-sensitive by default. Go back and try the previous block, changing the pattern to "shakespeare" to see this.

## Dates
The key to working with dates is that R needs to know that the column containing the date has a datatype of date (or datetime for timestamps). Regular R will guess, and the tidyverse will make a better guess.

Let's start with a dataset of campaign expenses from Maryland political committees:

```{r}
maryland_expenses <- read_csv("data/maryland_expenses.csv")

head(maryland_expenses)
```

Take a look at that first column, expenditure_date. It *looks* like a date, but see the `<chr` right below the column name? That means R thinks it's actually a character column. What we need to do is make it into an actual date column, which lubridate is very good at doing. It has a variety of functions that match the format of the data you have. In this case, the current format is `m/d/y`, and the lubridate function is called `mdy` that we can use with mutate:

### Task 8: Turning a character date into a real date

**Task** Run the following code and describe the change in the expenditure_date column.

```{r}
maryland_expenses <- maryland_expenses |> mutate(expenditure_date=mdy(expenditure_date))

head(maryland_expenses)
```

**Answer:**The lubridate mdy command is taking the date that is listed, and turning it into the commonly accepted format of YYYY-MM-DD, the mdy describes the input not the output.

Lubridate has functions for basically any type of character date format: mdy, ymd, even datetimes like ymd_hms.

That's less code and less weirdness, so that's good.

But to get clean data, I've installed a library and created a new field so I can now start to work with my dates. That seems like a lot, but don't think your data will always be perfect and you won't have to do these things.

Still, there's got to be a better way. And there is.

Fortunately, `readr` anticipates some date formatting and can automatically handle many of these issues (indeed it uses lubridate under the hood). When you are importing a CSV file, be sure to use `read_csv`, not `read.csv`.
#DL question, wait I dont understand originally you brought in this spreadsheet using the read_csv command not the read.csv command so why didnt it come in with the mdy already ran/dates cleaned up? or have I misunderstood something? Or are you saying that the _ vs . prepares it to be accessible by readr, not that the _ command itself is the readr auto cleanup command?

### Task 9: Creating a new date column from existing dates using mutate

But you're not done with lubridate yet. It has some interesting pieces parts we'll use elsewhere.

For example, in spreadsheets you can extract portions of dates - a month, day or year - with formulas. You can do the same in R with lubridate. Let's say we wanted to add up the total amount spent in each month in our Maryland expenses data.

We could use formatting to create a Month field but that would group all the Aprils ever together. We could create a year and a month together, but that would give us an invalid date object and that would create problems later. Lubridate has something called a floor date that we can use.

Basically, the floor_date() function sets dates to the beginning of a specified time period, such as the beginning of a month. It's commonly used to group data by month and create consistent time periods for a time series analysis.

So to follow along here, we're going to use a new function, `mutate`, to create a month field, group by to lump them together, summarize to count them up and arrange to order them. We're just chaining things together. Mutate is the key here because it allows us to create a new column from existing data.

**Task** Run the following code

```{r}
maryland_expenses |>
  mutate(month = floor_date(expenditure_date, "month")) |>
  group_by(month) |>
  summarise(total_amount = sum(amount)) |>
  arrange(desc(total_amount))
```

So the month of June 2022 had the most expenditures by far in this data.

Describe the values in the new `month` column - what do you think is going on there?

**Answer** Well like you said it's pretty straight forward, you created a new column with mutate, specified that it would be called month, then that column would have been an exact copy of the expediture_date column except you used the floor_date command which changed the values in the day part of the date to 01 in every field. Then you did a pivot table so you would only get one row for each month beacuse there would have been tons of rows for each month. 

### Task 10: Mutate

Often the data you have will prompt questions that it doesn't immediately answer. Election results, for example, have raw vote totals but we often don't use those to make comparisons between candidates unless the numbers are small. We need percentages!

First, we'll import a dataset of county-level gubernatorial results from Maryland's 2022 general election that is in the data folder in this chapter's pre-lab directory. We'll use this to explore ways to create new information from existing data.

**Task**

```{r}
general_22 <- read_csv('data/md_gov_county.csv')
```

Let's add a column called `percent_moore` for the percentage of votes that went to Wes Moore, the Democratic candidate who won the election, in each county. The code to calculate a percentage is pretty simple. Remember, with `summarize`, we used `n()` to count things. With `mutate`, we use very similar syntax to calculate a new value -- a new column of data -- using other values in our dataset.

To calculate a percentage, we need both the number of votes for Moore but also the total number of votes. We'll use mutate to create both columns. The first will be total votes, and the second will be the percentage for Moore. The key here is to save the dataframe to itself so that our changes stick.

**Task** Let's add a new column based on an existing column. Run the following code to create a new column called `total_votes` based on the votes cast for each candidate, and then to create a new column called (#dl comment: pct_moore)

```{r}
general_22 <- general_22 |>
  mutate(
    total_votes = cox + moore + lashar + wallace + write_ins,
    pct_moore = moore/total_votes
  )
```

Describe what you think this code is doing below.

**Answer** The top line is saving a variable with the same name as the old variable so it overwrites, then its saying what that the old variable will be modified by mutating (adding a column) called total_votes which is the sum of all the other vote count columns, then the comma means that the mutate command is happening again this time the column is called pct_moore. That column is equal to the total amount of votes moore got divided by the column value you just created total_votes.It is left in decimal form but if we wanted it in percent form we would modify the pct_moore line with a multiple of 100

#dlcomment, I'm respectfully trying to take your note from a previous assignment about concission but I didn't know how to answer this succinctly without sounding like I'm just saying exactly whats in the TASK line which wouldn't show you that I understand the material

### Task 11: Better percentage calculation

**Task** Run the following code to make our new column called `pct_moore` show a percentage instead of a decimal.

```{r}
# make it a percentage
general_22 <- general_22 |>
  mutate(
    pct_moore = (moore/total_votes)*100
  )
```

### Task 12: Mutate with ordering

**Task** Run the following code to order by our new column.

```{r}
# better ordering?
general_22 <- general_22 |>
  mutate(
    pct_moore = (moore/total_votes)*100
  ) |>
  arrange(desc(pct_moore))
```

How did the answer change from the previous task, and why?

**Answer**The only change was the arrange command, it ordered the districts in order of which counties supported Moore the most to the least (by percentage) if we wanted to say see which county had the most moore voters we would sort by "moore"

### Task 13: Mutate with ordering, part 2

**Task** Run the following code to order by our new column, but in ascending order

```{r}
# better ordering ?
general_22 |>
  arrange(pct_moore)
```

Is this a more interesting or useful answer? Why?

**Answer** I mean I think it depends on what you're looking for/what story you're writing. For instance if you were writing a story about the Governors public appearances in this term and had a theory that he was deliberately trying to shore up support in counties he did comparatively poorly in then you would want it in ascending order. Is that what you were looking for?

### Task 14: Standardize existing data using mutate

Mutate is also useful for standardizing data - for example, making different spellings of, say, campaign spending recipients.

Let's use our Maryland expenditure data and focus in particular on the `payee_name` column.

You'll notice that there's a mix of styles: lower-case and upper-case names like "Anedot" and "ANEDOT", for example. R will think those are two different payees, and that will mean that any aggregates we create based on payee_name won't be accurate.

So how can we fix that? Mutate - it's not just for math! And a function called `str_to_upper` that will convert a character column into all uppercase.

**Task** Run the following code:

```{r}
standardized_maryland_expenses <- maryland_expenses |>
  mutate(
    payee_upper = str_to_upper(payee_name)
)
```

**Task** Search the Internet for tidyverse functions similar to str_to_upper. Name at least two and describe what they do. If you use ChatGPT for this, include the question you submitted.

**Answer**
1. toupper() according to: https://stackoverflow.com/questions/16516593/convert-from-lowercase-to-uppercase-all-values-in-all-character-variables-in-dat
2. **AI DISCLOSURE** in accordance with the Use of AI section in the syllabus I am disclosing I used AI for this next answer (sorry to sound so up tight this first time its just they scared the bejesus out of us during orientation about unauthorized use of AI so I am very deliberative)
Claude Conversation:
David: For the tidyverse library of the programming language R, if I want to take a cell that has letters in it and change all of them to capital letters what are all the different command methods I can use to accomplish that goal? Please be AS SUCCINCT AS POSSIBLE, like a short list with a short example for each. I am already aware of the str_to_upper command as well as the toupper command.

Claude: Here are additional methods beyond str_to_upper() and toupper():
str_to_title() with manipulation:
r
   str_to_title("hello") %>% str_replace_all(" ", "")
str_replace_all() with regex:
r
   str_replace_all("hello", "(.)", "\\U\\1")
str_transform() with custom function:
r
   str_transform("hello", toupper)
map_chr() with ASCII manipulation:
r
   map_chr(str_split("hello", "")[[1]], ~intToUtf8(utf8ToInt(.x) - 32))
chartr() base R function:
r
   chartr("a-z", "A-Z", "hello")
Note: Methods 3-4 are more creative workarounds; str_to_upper() and toupper() remain the most straightforward approaches.

David: 5 seems the simplest

Claude: You're right! chartr() is indeed very simple and efficient:
r
chartr("a-z", "A-Z", "hello")
# Returns: "HELLO"
It directly translates characters from one set to another - no regex, no piping, just a straightforward character translation. It's a base R function that's often overlooked but perfect for simple case conversions.
**End of conversation**
Final answer is chartr("a-z", "A-Z", "hello")

There are lots of potential uses for standardization - addresses, zip codes, anything that can be misspelled or abbreviated.

### Task 15: Create a new column using case_when

Mutate is even more useful when combined with some additional functions. Let's keep rolling with our expenditure data. Take a look at the address column: it contains a full address, including the state, spelled out. It would be useful to have a separate `state` column with an abbreviation. We can check to see if a state name is contained in that column and then populate a new column with the value we want, using the functions `str_detect` and `case_when`. We can identify the state by the following pattern: a space, followed by the full name, followed by another space. So, " Maryland ". The `case_when` function handles multiple variations, such as if the state is Maryland or the state is Texas, etc. Crucially, we can tell R to populate the new column with `NA` if it doesn't find a match.
#dl comment OK and then we could create a dataframe with a filter for every NA and display the address column so we know what states to modify our code to add to the lists. Or I am assuming soon we will learn how to generalize the values in the str_detect line to bring in values from a separate data frame with state names in one column and abbreviations in another. Just thinking out loud.

**Task** Run the following code and look at the output. Then write a sentence or two describing what you think the mutate statement is doing step by step.

**Answer** Creating a new dataframe from the original, creating a column within that data frame called state, the case when gives you the ability to search for a bunch of different things like a massive "or" function. Not sure if the case when can exist without the string detect function, like if there was just one criteria you were searching for.

```{r}
maryland_expenses_with_state <- maryland_expenses |>
  mutate(
    state = case_when(
        str_detect(address, " Maryland ") ~ "MD",
        str_detect(address, " California ") ~ "CA",
        str_detect(address, " Washington ") ~ "WA",
        str_detect(address, " Louisiana ") ~ "LA",
        str_detect(address, " Florida ") ~ "FL",
        str_detect(address, " North Carolina ") ~ "NC",
        str_detect(address, " Massachusetts ") ~ "MA",
        str_detect(address, " West Virginia ") ~ "WV",
        str_detect(address, " Virginia ") ~ "VA",
        .default = NA
      )
  )
```

There's a lot going on here, so let's unpack it. It starts out as a typical mutate statement, but `case_when` introduces some new things. Each line checks to see if the pattern is contained in the address column, followed by `~` and then a value for the new column for records that match that check. You can read it like this: "If we find ' Maryland ' in the address column, then put 'MD' in the state column" for Maryland and then a handful of states, and if we don't match any state we're looking for, make state `NA`.

We can then use our new `state` column in group_by statements to make summarizing easier.

**Task** Run the following code.

```{r}
maryland_expenses_with_state |>
  group_by(state) |>
  summarize(total = sum(amount)) |>
  arrange(desc(total))
```

Does this answer make sense to you? Why or why not?

**Answer** Makes sense to me, total expenses from each state. I would probably drill down a bit more with what states we listed to bring the unknown state number down a bit.

Mutate is there to make your data more useful and to make it easier for you to ask more and better questions of it.

### Task 16: More questions

Now that you have seen how to use mutate, filtering and dates, give me three questions about either the UMD course data or the Maryland expenditure data that you could ask that would make use of some or all of those new functions. They can be better versions of the questions from the previous pre-lab.

**Answer**

1.  Are most of the expenditures from in state or out of state?

2.  I could use the floor date to see how the number of classes changed per year

3.  I could use the mutate function on the expenditure data to break down the spending by state in terms of percentage of total spent
